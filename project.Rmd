---
title: "What Makes A Successful Startup Company?"
author: "Lab Group - Tessa Grabowski, Himanshu Jain, Paul Noujaim, Tri Truong"
subtitle: ''
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, comment = NA, 
                      message = FALSE, warning = FALSE,
                      fig.height=6, fig.width = 9, fig.align = "center")
```



# Introduction

Our general research question to find out what are the most important factors
in contributing to the success of a startup project. Our dataset is comprised
of the statistics from over 300,000 Kickstarter proposals, collected directly
from the Kickstarter Platform (found on Kaggle). It includes variables that 
could be essential to determining the success of a startup such as, the amount 
of money pledged to a startup, the number of backers the project has, or the 
industry the company is in. The key variable we are looking at is the 
binary variable called "state", which shows which startups were successful 
and which were not. This will be our response variable in the analyses. We think 
this analysis of this data would be particularly useful if any member of our 
group wanted to start our own creative project by giving us an idea about which 
factors are key in indicating the future success of a startup.

Kickstarter is a global crowdfunding platform where different products can be 
listed in different categories like music, arts, technology etc. Till date, 
the company has received over $4.6 billion in funding from almost 17.2 million
backers. We believe that it would be interesting to analyze the data from this 
company to recognize the reason behind its success and how useful it might be 
for upcoming projects. Many new products are launched everyday so it would also
provide an insight to the developer as to what products would have a higher 
rate of success. 

The different variables in this dataset are- ID, name (name of the project), 
category(category of the project), main category, currency, deadline, goal 
(amount of money required), launched, pledged (amount of money the project got), 
state, backers, country, and usd pledged. We believe that some of these 
variables would be really important in providing us an insight about the 
data/company. 

# Data Analysis Plan

```{r packages}
library(tidyverse)
library(class)
library(broom)
library(usethis)
library(dplyr)
library(infer)
```
```{r reading_the_data}
kickstart <- read_csv("data/ks-projects-201612.csv")
glimpse(kickstart)
```

```{r success_rate}
kickstart%>%
  group_by(state)%>%
  filter(state=="canceled"| state=='failed'|state=='live'|state=='successful'|
           state=='suspended'|state=='undefined')%>%
  count()
```
From this table, we see that most of the companies have a state of either failed
or successful. Thus when we are analyzing our data, we will filter it to only 
include these companies. We are interested in what makes a project successful
versus unsuccessful, so any entry with a different state will be irrelevant to 
our analysis.

```{r category_wise}
kickstart%>%
  group_by(category)%>%
  count()%>%
  filter(n > 100)
```
```{r main_categories}
kickstart%>%
  group_by(main_category)%>%
  count()%>%
  filter(n > 100)
```
Looking at the numbers in the categories and main categories, we can get a
better idea at what kind of projects are more successful than others. Knowing
this will help us narrow down what the crowd is interested in investing in, and 
what fields people are more likely to succeed in if they were to create their
own project. 

The variable `pledged` tells the amount of money pledged by the crowd, or users
of the site. 

```{r pledged_needed}
pledged_needed <- kickstart %>%
  group_by(state) %>%
  filter(state=='failed'|state=='successful') %>%
  summarise(mean = mean(pledged), 
            min = min(pledged),
            max = max(pledged)) %>%
  mutate(range = max - min)

pledged_needed

ggplot(data = pledged_needed, mapping = aes(x = state, y = mean, 
                                            fill = state)) +
  geom_bar(stat = "identity") +
  theme_bw() +
  labs(title = "Successful Projects Generally Receive More Pledged Money",
       x = "State", y = "Pledged ($)", fill = "State")
```
This table shows that there is a large gap between the amount of money 
pledged to projects that failed as opposed to those that were successful. The
average amount of money pledged to successful projects is more than ten 
times greater than that pledged to failed projects. We can also see this in the 
bar plot above, as the bar for successful projects is significantly higher than 
the bar for failed. In addition, the range of money pledged to successful 
projects is significantly greater than the range of failed projects. 
These statistics suggest that the variable `pledged`has an effect on determining
the state of a project.

Another variable we are interested in is `goal`. `Goal`gives the amount of money
needed by a creator to fund and finish their project. 

```{r goal_bar}
avg_goal <- kickstart %>%
  group_by(state) %>%
  filter(state=='failed'|state=='successful') %>%
  summarise(mean_goal = mean(goal))

ggplot(data = avg_goal, mapping = aes(x = state, y = mean_goal, fill = state)) +
  geom_bar(stat = "identity") +
  theme_bw() +
  labs(title = "Failed Projects Generally Require More Money",
       x = "State", y = "Average Goal ($)", fill = "State")
```
This visualization shows that failed projects generally were much more expensive
to create than successful projects. This is very useful in our analysis, since
it suggests that there is possibly a threshold to how much money can be required
by the creator before the project becomes unreasonable and fails. 

In our analysis it could be interesting to compare the goal of a creator to how 
much they received from pledged money as well. Looking at these two variables 
and how they interact could be very telling of the outcome of the project.

# Codebook

We can see that there are 323750 rows and 13 relevant columns in the dataset
we are using.

Variable-> Label
ID -> ID of the project that was listed
name-> Name of the Project that was listed
category->Category of the project that was listed
main_category-> Main catefgory to which the project belonged
currency-> The currency funding was requested In
deadline-> The deadline to get the required funding
goal-> The amount that was requested
launched-> The date when the funding was started
pledged-> The amount pledged by the backers
state-> The final outcome of the project
backers-> Number of people who funded the project
country-> Country where the project was launched
usd pledged-> US Dollars that the project got

Field Name->Value Label
currency 
AUD Australian Dollars
CAD Canadian Dollars
CHF Swiss Franc
DKK Danish Krone
EUR Euro
GBP Pound Sterling
MXN Mexican Peso
NOK Norwegian Krone
NZD New Zealand Dollar
SEK Swedish krona
USD US Dollar

country 
AT Austria
AU Australia
CA Canada
CH Switzerland
DE Germany
DK Denmark
ES Spain
FR France
GB United Kingdom
IE Ireland
IT Italy
MX Mexico
NL Netherlands
NO Norway
NZ New Zealand
SE Sweden
SG Singapore
US United States


# Statistical Methods 

Further, in our analysis, we will use other statistical methods to answer our 
question of what makes a project successful. We will create our own hypothetical
projects and determine statistics for the needed variables. Then we will use
the knn method to predict if this project will be successful or not based on the
data we have. 

We also will use confidence intervals for the mean amount of money required,
number of backers necessary, amount pledged, etc. that we expect a successful
company to have. 

Finally, we will use a linear regression model to figure out which variables are
the most significant in determining the eventual 'state' of the startup, 
whether they ended up being successful or unsuccessful.

Using these methods, we will hopefully be able to determine why certain projects
are successful while others are not and use this information to help us in the
future if we ever want to start our own companies.



## K-NN 

```{r}
kickstart_new <- kickstart %>%
  select(-(X14:X17)) %>%
  rename(usd_pledged = `usd pledged`) %>%
  na.omit()
```
```{r}

kickstart_1 <- kickstart_new %>%
  group_by(state) %>%
  sample_frac(0.1) %>%
  ungroup()
```




```{r new_variables}
kickstart_mutated <- kickstart_new%>%
  mutate(
    goal = ((goal- mean(goal)) / sd(goal)),
    pledged = ((pledged - mean(pledged)) / sd(pledged)),
    backers = ((backers - mean(backers)) / sd(backers))
  )
```

```{r set_seed}
set.seed(03052020)
indices <- sample(nrow(kickstart_1), 2500)
```

```{r}
kickstart_train <- kickstart_new %>%
  slice(-indices) %>% 
  select(category, main_category, goal, backers, usd_pledged)
```

```{r new_datasets}
kickstart_train <- kickstart_1 %>%
  slice(-indices) %>%
  select(goal, pledged,backers) 


kickstart_test <- kickstart_1 %>%
  slice(indices) %>%
  select(category, main_category, goal, backers, usd_pledged)

train_state <- kickstart_new %>%
  slice(-indices) %>%
  pull(state)

true_state <- kickstart_new %>%

  select(goal, pledged,backers)
  
train_state <- kickstart_1 %>%
  slice(-indices) %>%
  pull(state)

#kickstart_train
#kickstart_test
#train_state
```

```{r true_types}
true_state <- kickstart_1 %>%
  slice(indices) %>%
  pull(state)


kickstart_train
kickstart_test
train_state
true_state
```



```{r knn_best}
values <- numeric(157) 
for(i in 1:79) {
  trains_knn <- knn(kickstart_train, kickstart_test, train_state, 
                    k = (2*i)-1, prob = FALSE, use.all = FALSE)
  x <- mean(trains_knn == true_state)  
  values[(2*i)-1] <- x
}
tibble(values)
which.max(values)
```
k = 1?

```{r create_values}
mean_goal <- kickstart_new %>%
  group_by(state) %>%
  filter(state=='successful') %>%
  summarise(mean_goal = mean(goal))

mean_pledged <- kickstart_new %>%
  group_by(state) %>%
  filter(state=='successful') %>%
  summarise(mean_pledged = mean(pledged))

mean_backers <- kickstart_new %>%
  group_by(state) %>%
  filter(state=='successful') %>%
  summarise(mean_backers = mean(backers))

mode_category <- kickstart_new %>%
  group_by(main_category) %>%
  count()%>%
  arrange(desc(n))
  

mode_country <- kickstart_new %>%
  group_by(country) %>%
  count() %>%
  arrange(desc(n))

#mean_goal
#mean_pledged
#mean_backers
#mode_category
#mode_country
```

```{r predicting_project_succes}
new_project <- tibble(goal = c(1000, 9627.803, 27000),
                      pledged = c(925, 21480.74, 24000),
                      backers = c(15, 253.86, 750))

train <- kickstart_new %>% 
  select(goal, pledged, backers)

success_state <- kickstart_new %>% 
  pull(state) 

mod_knn <- knn(train, new_project, success_state, k = 125, prob = F, use.all = T)
mod_knn
```
-pledged and goal have more significant effect on determining state than backers
-but backers do effect state (first example, even if pledged below goal)



## Confidence Intervals

```{r}
kickstart_new %>%
   filter(state == "successful") %>% 
  specify(response = usd_pledged) %>% 
  generate(reps = 100, type = "bootstrap") %>% 
  calculate(stat = "mean") %>%
  get_ci(level = .95)
```

```{r}
kickstart_new %>%
   filter(state == "successful") %>% 
  specify(response = backers) %>% 
  generate(reps = 100, type = "bootstrap") %>% 
  calculate(stat = "mean") %>%
  get_ci(level = .95)
```

```{r}
kickstart_new %>%
   filter(state == "successful") %>% 
  specify(response = goal) %>% 
  generate(reps = 100, type = "bootstrap") %>% 
  calculate(stat = "mean") %>%
  get_ci(level = .95)
```

## Linear Model 

```{r all the variables}


m_full <- lm(state ~ main_category + goal + backers + usd_pledged + country
            , data = kickstart_new)
m_full <- lm(state ~ goal + backers + pledged,
            data = kickstart_new)

m_full <- glm(state ~ goal + backers + pledged + main_category + country,
            data = kickstart_1, family = "binomial")


tidy(m_full)
glance(m_full)


#check lab 7! for fitting logistic model and comparing with knn
#lecture with knn shows predictions possibly
```



p-value for country is around 0.9 so very large so we expect it to not be
in the backward 


```{r full model}
step_full <- step(m_full, direction = "backward", trace = FALSE, 
                  results = "hide")
tidy(step_full)
glance(step_full)

```

```{r prediction_accuracy}
pred_log_odds <- augment(step_full, newdata = kickstart_test) %>% 
  mutate(prob = exp(.fitted)/ (1 + exp(.fitted))) %>%
  mutate(class = ifelse(prob > .5, "successful", "failed")) %>%
  na.omit() %>%
  pull(class)

# pred_log_odds
mean(true_state == pred_log_odds)
```

```{r}
#backers_out <- kickstart_new %>%
#  filter(backers <= 500) %>%
#  filter(pledged <= 25000)
```

```{r}
#m_pledged <- lm(pledged ~ backers, backers_out)
#tidy(m_pledged)
#glance(m_pledged)
#m_pledged_aug <- augment(m_pledged)
```

```{r}
ggplot(step_full, mapping = aes(x = .fitted, y = .resid)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, color = "blue", lty = 2) 
```

## Check Independence

```{r conditions_check_independence}
full_model <- augment(step_full)
ggplot(data = full_model, aes(x = 1:nrow(full_model), y = .resid)) +
geom_point() +
labs(x = "Index", y = "Residual", title="Residuals vs Index",
     subtitle = "Both the variables seems independent") +
  theme_minimal(base_size = 16)
```

```{r residual_variance}
ggplot(data = full_model, aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0, lty = 3, color = "gray") +
  labs(title="Residuals vs the fitted value", y = "Residuals", 
       x = expression(hat(y)), 
       subtitle="We can see constant variance and distrbution to be around 0") +
  theme_minimal(base_size = 16)
```

```{r histogram}
ggplot(data = full_model, aes(x = .resid)) +
  geom_histogram(binwidth = .5) +
  labs(title="Count vs Residuals", 
       subtitle="The histogram seems to be centered around 0",
       x = "Residuals", y = "Count") +
  theme_minimal(base_size = 16)
```

